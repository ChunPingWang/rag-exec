{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例 19：完整的 Fine-Tuning 評估系統\n",
    "\n",
    "包含多種評估指標和完整報告的評估系統！\n",
    "\n",
    "## 學習目標\n",
    "- 建立完整的評估流程\n",
    "- 了解多維度評估方法\n",
    "- 學會生成評估報告\n",
    "\n",
    "## 前置需求\n",
    "- LM Studio 運行中，Local Server 已啟動\n",
    "- 安裝 openai 套件：`pip install openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 匯入套件並設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"not-needed\"\n",
    ")\n",
    "\n",
    "print(\"已連接到 LM Studio！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 建立完整的模型評估器類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    模型評估器\n",
    "    用於評估 Fine-Tuning 的效果\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model, finetuned_model=None):\n",
    "        \"\"\"\n",
    "        初始化評估器\n",
    "\n",
    "        參數：\n",
    "            base_model: 原始模型名稱\n",
    "            finetuned_model: 微調後模型名稱（可選）\n",
    "        \"\"\"\n",
    "        self.base_model = base_model\n",
    "        self.finetuned_model = finetuned_model\n",
    "        self.results = []\n",
    "        self.client = client\n",
    "\n",
    "    def get_response(self, model, question, system_prompt=None):\n",
    "        \"\"\"取得模型回應\"\"\"\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": question})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def score_response(self, question, response, criteria):\n",
    "        \"\"\"\n",
    "        使用 AI 評分回答品質（多維度）\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"請評估以下回答的品質，針對每個標準給予 1-5 分。\n",
    "\n",
    "問題：{question}\n",
    "\n",
    "回答：{response}\n",
    "\n",
    "評估標準：\n",
    "{criteria}\n",
    "\n",
    "請用以下 JSON 格式回答（只輸出 JSON）：\n",
    "{{\n",
    "    \"accuracy\": <1-5>,\n",
    "    \"completeness\": <1-5>,\n",
    "    \"clarity\": <1-5>,\n",
    "    \"usefulness\": <1-5>,\n",
    "    \"overall\": <1-5>,\n",
    "    \"comment\": \"簡短評語（一句話）\"\n",
    "}}\"\"\"\n",
    "\n",
    "        eval_response = self.client.chat.completions.create(\n",
    "            model=self.base_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            result = eval_response.choices[0].message.content\n",
    "            start = result.find('{')\n",
    "            end = result.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                return json.loads(result[start:end])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return {\"overall\": 0, \"comment\": \"評估失敗\"}\n",
    "\n",
    "    def evaluate_single(self, question, system_prompt=None):\n",
    "        \"\"\"\n",
    "        評估單一問題\n",
    "        \"\"\"\n",
    "        criteria = \"\"\"\n",
    "        - accuracy（準確性）：資訊是否正確\n",
    "        - completeness（完整性）：是否涵蓋所有重點\n",
    "        - clarity（清晰度）：是否容易理解\n",
    "        - usefulness（實用性）：是否有幫助\n",
    "        - overall（整體）：綜合評分\n",
    "        \"\"\"\n",
    "\n",
    "        result = {\"question\": question}\n",
    "\n",
    "        # 評估原始模型\n",
    "        base_response = self.get_response(\n",
    "            self.base_model, question, system_prompt\n",
    "        )\n",
    "        base_score = self.score_response(question, base_response, criteria)\n",
    "        result[\"base\"] = {\n",
    "            \"response\": base_response,\n",
    "            \"scores\": base_score\n",
    "        }\n",
    "\n",
    "        # 如果有微調模型，也進行評估\n",
    "        if self.finetuned_model:\n",
    "            ft_response = self.get_response(\n",
    "                self.finetuned_model, question, system_prompt\n",
    "            )\n",
    "            ft_score = self.score_response(question, ft_response, criteria)\n",
    "            result[\"finetuned\"] = {\n",
    "                \"response\": ft_response,\n",
    "                \"scores\": ft_score\n",
    "            }\n",
    "\n",
    "        self.results.append(result)\n",
    "        return result\n",
    "\n",
    "    def evaluate_batch(self, questions, system_prompt=None):\n",
    "        \"\"\"\n",
    "        批次評估多個問題\n",
    "        \"\"\"\n",
    "        print(f\"開始評估 {len(questions)} 個問題...\\n\")\n",
    "\n",
    "        for i, q in enumerate(questions, 1):\n",
    "            print(f\"[{i}/{len(questions)}] 評估中: {q[:30]}...\")\n",
    "            self.evaluate_single(q, system_prompt=system_prompt)\n",
    "\n",
    "        return self.get_summary()\n",
    "\n",
    "    def get_summary(self):\n",
    "        \"\"\"\n",
    "        取得評估摘要\n",
    "        \"\"\"\n",
    "        if not self.results:\n",
    "            return \"尚無評估結果\"\n",
    "\n",
    "        summary = {\n",
    "            \"total_questions\": len(self.results),\n",
    "            \"base_model\": {\n",
    "                \"avg_overall\": 0,\n",
    "                \"avg_accuracy\": 0,\n",
    "                \"avg_clarity\": 0,\n",
    "                \"avg_completeness\": 0,\n",
    "                \"avg_usefulness\": 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 計算原始模型平均分數\n",
    "        base_scores = [r[\"base\"][\"scores\"] for r in self.results]\n",
    "        for metric in [\"overall\", \"accuracy\", \"clarity\", \"completeness\", \"usefulness\"]:\n",
    "            values = [s.get(metric, 0) for s in base_scores if s.get(metric, 0) > 0]\n",
    "            if values:\n",
    "                summary[\"base_model\"][f\"avg_{metric}\"] = sum(values) / len(values)\n",
    "\n",
    "        # 如果有微調模型的結果\n",
    "        if self.finetuned_model and \"finetuned\" in self.results[0]:\n",
    "            summary[\"finetuned_model\"] = {\n",
    "                \"avg_overall\": 0,\n",
    "                \"avg_accuracy\": 0,\n",
    "                \"avg_clarity\": 0,\n",
    "                \"avg_completeness\": 0,\n",
    "                \"avg_usefulness\": 0\n",
    "            }\n",
    "            ft_scores = [r[\"finetuned\"][\"scores\"] for r in self.results]\n",
    "            for metric in [\"overall\", \"accuracy\", \"clarity\", \"completeness\", \"usefulness\"]:\n",
    "                values = [s.get(metric, 0) for s in ft_scores if s.get(metric, 0) > 0]\n",
    "                if values:\n",
    "                    summary[\"finetuned_model\"][f\"avg_{metric}\"] = sum(values) / len(values)\n",
    "\n",
    "            # 計算改善幅度\n",
    "            summary[\"improvement\"] = {}\n",
    "            for metric in [\"overall\", \"accuracy\", \"clarity\"]:\n",
    "                base_val = summary[\"base_model\"][f\"avg_{metric}\"]\n",
    "                ft_val = summary[\"finetuned_model\"][f\"avg_{metric}\"]\n",
    "                summary[\"improvement\"][metric] = ft_val - base_val\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def print_report(self):\n",
    "        \"\"\"\n",
    "        印出評估報告\n",
    "        \"\"\"\n",
    "        summary = self.get_summary()\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"          Fine-Tuning 評估報告\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        print(f\"\\n評估問題數：{summary['total_questions']}\")\n",
    "\n",
    "        print(f\"\\n┌{'─'*58}┐\")\n",
    "        print(f\"│ 原始模型 ({self.base_model})\")\n",
    "        print(f\"├{'─'*58}┤\")\n",
    "        base = summary['base_model']\n",
    "        print(f\"│   整體評分：{base['avg_overall']:.2f}/5\")\n",
    "        print(f\"│   準確性：  {base['avg_accuracy']:.2f}/5\")\n",
    "        print(f\"│   完整性：  {base['avg_completeness']:.2f}/5\")\n",
    "        print(f\"│   清晰度：  {base['avg_clarity']:.2f}/5\")\n",
    "        print(f\"│   實用性：  {base['avg_usefulness']:.2f}/5\")\n",
    "        print(f\"└{'─'*58}┘\")\n",
    "\n",
    "        if \"finetuned_model\" in summary:\n",
    "            print(f\"\\n┌{'─'*58}┐\")\n",
    "            print(f\"│ 微調模型 ({self.finetuned_model})\")\n",
    "            print(f\"├{'─'*58}┤\")\n",
    "            ft = summary['finetuned_model']\n",
    "            print(f\"│   整體評分：{ft['avg_overall']:.2f}/5\")\n",
    "            print(f\"│   準確性：  {ft['avg_accuracy']:.2f}/5\")\n",
    "            print(f\"│   完整性：  {ft['avg_completeness']:.2f}/5\")\n",
    "            print(f\"│   清晰度：  {ft['avg_clarity']:.2f}/5\")\n",
    "            print(f\"│   實用性：  {ft['avg_usefulness']:.2f}/5\")\n",
    "            print(f\"└{'─'*58}┘\")\n",
    "\n",
    "            print(f\"\\n┌{'─'*58}┐\")\n",
    "            print(f\"│ 改善幅度\")\n",
    "            print(f\"├{'─'*58}┤\")\n",
    "            imp = summary[\"improvement\"]\n",
    "            for metric, value in imp.items():\n",
    "                arrow = \"↑\" if value > 0 else \"↓\" if value < 0 else \"→\"\n",
    "                print(f\"│   {metric}：{arrow} {value:+.2f}\")\n",
    "            print(f\"└{'─'*58}┘\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 建立評估器並準備測試問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立評估器\n",
    "evaluator = ModelEvaluator(\n",
    "    base_model=\"gpt-oss-120b\",\n",
    "    # finetuned_model=\"my-finetuned-model\"  # 如果有微調模型\n",
    ")\n",
    "\n",
    "# 測試問題集\n",
    "test_questions = [\n",
    "    \"什麼是變數？請用簡單的方式解釋。\",\n",
    "    \"Python 中 list 和 dictionary 有什麼差別？\",\n",
    "    \"如何處理程式中的錯誤？\",\n",
    "    \"什麼是遞迴？請舉例說明。\",\n",
    "    \"解釋什麼是 API，以及為什麼要用它。\"\n",
    "]\n",
    "\n",
    "print(f\"準備評估 {len(test_questions)} 個問題\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 執行評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行評估\n",
    "system_prompt = \"你是一位程式設計教師，用簡單的方式回答問題。\"\n",
    "\n",
    "evaluator.evaluate_batch(\n",
    "    test_questions,\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 查看評估報告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 印出報告\n",
    "evaluator.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 查看詳細結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每個問題的詳細評估\n",
    "print(\"\\n=== 詳細評估結果 ===\")\n",
    "\n",
    "for i, result in enumerate(evaluator.results, 1):\n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    print(f\"問題 {i}：{result['question']}\")\n",
    "    print(f\"{'─'*60}\")\n",
    "    \n",
    "    base = result['base']\n",
    "    scores = base['scores']\n",
    "    \n",
    "    print(f\"\\n回答：{base['response'][:150]}...\")\n",
    "    print(f\"\\n評分：\")\n",
    "    print(f\"  - 整體：{scores.get('overall', 'N/A')}/5\")\n",
    "    print(f\"  - 準確性：{scores.get('accuracy', 'N/A')}/5\")\n",
    "    print(f\"  - 清晰度：{scores.get('clarity', 'N/A')}/5\")\n",
    "    print(f\"  - 評語：{scores.get('comment', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 匯出評估結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(evaluator, filename):\n",
    "    \"\"\"\n",
    "    匯出評估結果為 JSON 檔案\n",
    "    \"\"\"\n",
    "    export_data = {\n",
    "        \"summary\": evaluator.get_summary(),\n",
    "        \"details\": evaluator.results\n",
    "    }\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"評估結果已匯出到 {filename}\")\n",
    "\n",
    "# 匯出結果\n",
    "export_results(evaluator, \"evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評估指標說明\n",
    "\n",
    "### 五個評估維度\n",
    "\n",
    "| 維度 | 英文 | 說明 |\n",
    "|------|------|------|\n",
    "| 準確性 | accuracy | 資訊是否正確無誤 |\n",
    "| 完整性 | completeness | 是否涵蓋所有重點 |\n",
    "| 清晰度 | clarity | 表達是否清楚易懂 |\n",
    "| 實用性 | usefulness | 對使用者是否有幫助 |\n",
    "| 整體 | overall | 綜合評分 |\n",
    "\n",
    "### 評分標準\n",
    "\n",
    "- **5 分**：優秀，完全符合標準\n",
    "- **4 分**：良好，大致符合標準\n",
    "- **3 分**：普通，基本符合標準\n",
    "- **2 分**：不佳，有明顯問題\n",
    "- **1 分**：很差，完全不符合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立你自己的評估\n",
    "\n",
    "# 1. 準備你的測試問題\n",
    "my_questions = [\n",
    "    \"你的問題 1\",\n",
    "    \"你的問題 2\",\n",
    "]\n",
    "\n",
    "# 2. 建立評估器\n",
    "# my_evaluator = ModelEvaluator(base_model=\"gpt-oss-120b\")\n",
    "\n",
    "# 3. 執行評估\n",
    "# my_evaluator.evaluate_batch(my_questions)\n",
    "\n",
    "# 4. 查看報告\n",
    "# my_evaluator.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恭喜完成所有範例！\n",
    "\n",
    "### 你學到了：\n",
    "\n",
    "1. **基礎對話**（範例 1-5）\n",
    "   - 與 Ollama 進行對話\n",
    "   - 多輪對話和串流輸出\n",
    "   - 系統提示詞和角色扮演\n",
    "\n",
    "2. **LM Studio 使用**（範例 6-11）\n",
    "   - OpenAI 相容 API\n",
    "   - 使用 OpenAI SDK\n",
    "   - 通用聊天程式\n",
    "\n",
    "3. **RAG 技術**（範例 12-14）\n",
    "   - 簡易 RAG 系統\n",
    "   - 向量搜尋\n",
    "   - 文件問答\n",
    "\n",
    "4. **Fine-Tuning 相關**（範例 15-19）\n",
    "   - 準備訓練資料\n",
    "   - 自訂 Ollama 模型\n",
    "   - 資料增強\n",
    "   - 模型評估\n",
    "\n",
    "### 下一步建議：\n",
    "\n",
    "- 嘗試用學到的技術建立自己的應用\n",
    "- 探索更多進階功能\n",
    "- 持續練習和實驗！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
