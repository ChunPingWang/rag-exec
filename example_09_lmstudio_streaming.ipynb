{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例 9：LM Studio 串流輸出\n",
    "\n",
    "即時顯示 AI 的回應，像 ChatGPT 一樣一個字一個字出現！\n",
    "\n",
    "## 學習目標\n",
    "- 使用 OpenAI SDK 實現串流輸出\n",
    "- 了解串流 API 的使用方式\n",
    "- 比較串流與非串流的差異\n",
    "\n",
    "## 前置需求\n",
    "- LM Studio 運行中，Local Server 已啟動\n",
    "- 安裝 openai 套件：`pip install openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 匯入套件並設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 建立客戶端\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"not-needed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 定義串流對話函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat_lmstudio(message):\n",
    "    \"\"\"\n",
    "    使用串流方式獲得 LM Studio 回應\n",
    "    \"\"\"\n",
    "\n",
    "    # 發送串流請求\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-oss-120b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        stream=True  # 啟用串流模式\n",
    "    )\n",
    "\n",
    "    print(\"AI：\", end=\"\", flush=True)\n",
    "\n",
    "    # 逐步接收並顯示回應\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full_response += content\n",
    "\n",
    "    print()  # 最後換行\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 測試串流輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"請用三句話介紹台灣。\"\n",
    "print(f\"問題：{question}\")\n",
    "print(\"-\" * 50)\n",
    "stream_chat_lmstudio(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 串流 vs 非串流比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def normal_chat(message):\n",
    "    \"\"\"非串流方式\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-oss-120b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompt = \"請解釋什麼是機器學習，用三個重點說明。\"\n",
    "\n",
    "print(\"=== 非串流模式 ===\")\n",
    "print(\"（需要等待完整回應...）\\n\")\n",
    "start = time.time()\n",
    "result = normal_chat(test_prompt)\n",
    "end = time.time()\n",
    "print(f\"AI：{result}\")\n",
    "print(f\"\\n等待時間：{end - start:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== 串流模式 ===\")\n",
    "print(\"（文字即時顯示）\\n\")\n",
    "start = time.time()\n",
    "stream_chat_lmstudio(test_prompt)\n",
    "end = time.time()\n",
    "print(f\"\\n總時間：{end - start:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 進階串流 - 收集完整回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chat_with_callback(message, on_chunk=None):\n",
    "    \"\"\"\n",
    "    串流對話，支援自訂處理函數\n",
    "    \n",
    "    參數：\n",
    "        message: 使用者訊息\n",
    "        on_chunk: 每收到一個片段時的處理函數\n",
    "    \n",
    "    回傳：\n",
    "        完整的回應文字\n",
    "    \"\"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-oss-120b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            full_response += content\n",
    "            \n",
    "            # 如果有提供處理函數，就呼叫它\n",
    "            if on_chunk:\n",
    "                on_chunk(content)\n",
    "    \n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自訂處理函數：計算字數\n",
    "char_count = 0\n",
    "\n",
    "def count_chars(chunk):\n",
    "    global char_count\n",
    "    char_count += len(chunk)\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "print(\"即時輸出並計算字數：\\n\")\n",
    "response = stream_chat_with_callback(\"什麼是 API？簡單解釋。\", on_chunk=count_chars)\n",
    "print(f\"\\n\\n總共收到 {char_count} 個字元\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 串流 API 解析\n",
    "\n",
    "### 關鍵設定\n",
    "```python\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-oss-120b\",\n",
    "    messages=[...],\n",
    "    stream=True  # 這個參數啟用串流\n",
    ")\n",
    "```\n",
    "\n",
    "### 處理串流回應\n",
    "```python\n",
    "for chunk in stream:\n",
    "    # chunk.choices[0].delta.content 包含這次收到的文字片段\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "```\n",
    "\n",
    "### 注意事項\n",
    "- `delta` 物件包含這次收到的增量內容\n",
    "- 需要檢查 `delta.content` 是否存在（可能是 None）\n",
    "- 使用 `flush=True` 確保即時輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試著用串流方式問一個需要長回答的問題\n",
    "my_question = \"請詳細解釋網路是如何運作的？\"\n",
    "\n",
    "print(f\"問題：{my_question}\")\n",
    "print(\"-\" * 50)\n",
    "stream_chat_lmstudio(my_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重點回顧\n",
    "\n",
    "1. **啟用串流**：設定 `stream=True`\n",
    "2. **處理片段**：使用 `for chunk in stream` 迭代\n",
    "3. **取得內容**：`chunk.choices[0].delta.content`\n",
    "4. **即時輸出**：使用 `print(..., end=\"\", flush=True)`\n",
    "\n",
    "## 下一步\n",
    "\n",
    "在下一個範例中，我們將學習如何查看 LM Studio 中可用的模型！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
