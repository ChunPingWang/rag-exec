{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例 1：與 AI 進行簡單對話\n",
    "\n",
    "這是最基本的使用方式，就像跟 AI 聊天一樣。\n",
    "\n",
    "## 學習目標\n",
    "- 了解如何使用 Python 與本地 AI 模型對話\n",
    "- 認識 Ollama API 的基本用法\n",
    "- 學會發送 HTTP 請求並處理回應\n",
    "\n",
    "## 前置需求\n",
    "- Ollama 運行中\n",
    "- 已下載 gpt-oss:120b 模型（或其他可用模型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 匯入必要的套件\n",
    "\n",
    "`requests` 是 Python 中最常用的 HTTP 請求套件，用來與 API 溝通。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 定義與 AI 對話的函數\n",
    "\n",
    "這個函數負責：\n",
    "1. 準備要發送給 AI 的資料\n",
    "2. 發送 HTTP POST 請求到 Ollama API\n",
    "3. 解析並返回 AI 的回應"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_ai(prompt):\n",
    "    \"\"\"\n",
    "    發送訊息給 AI 並獲得回應\n",
    "\n",
    "    參數：\n",
    "        prompt: 你想問 AI 的問題（字串）\n",
    "\n",
    "    回傳：\n",
    "        AI 的回應（字串）\n",
    "    \"\"\"\n",
    "\n",
    "    # Ollama 的 API 網址（在你的電腦上運行）\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "    # 準備要發送的資料\n",
    "    data = {\n",
    "        \"model\": \"gpt-oss:120b\",  # 使用的模型名稱\n",
    "        \"prompt\": prompt,          # 你的問題\n",
    "        \"stream\": False            # 不使用串流（一次返回完整回應）\n",
    "    }\n",
    "\n",
    "    # 發送請求給 Ollama\n",
    "    response = requests.post(url, json=data)\n",
    "\n",
    "    # 解析回應\n",
    "    result = response.json()\n",
    "\n",
    "    return result[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 測試對話功能\n",
    "\n",
    "讓我們問 AI 一個簡單的問題！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問 AI 一個問題\n",
    "question = \"什麼是人工智慧？請用簡單的方式解釋。\"\n",
    "\n",
    "print(f\"問題：{question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "answer = chat_with_ai(question)\n",
    "print(f\"AI 回答：{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間！\n",
    "\n",
    "試著修改下面的問題，問 AI 不同的事情："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在這裡輸入你自己的問題\n",
    "my_question = \"請告訴我三個學習程式設計的建議\"\n",
    "\n",
    "print(f\"我的問題：{my_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "my_answer = chat_with_ai(my_question)\n",
    "print(f\"AI 回答：{my_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重點回顧\n",
    "\n",
    "1. **API 網址**：`http://localhost:11434/api/generate` 是 Ollama 的本地 API 端點\n",
    "2. **請求格式**：使用 JSON 格式發送資料，包含 `model`、`prompt`、`stream` 三個欄位\n",
    "3. **回應處理**：API 返回的 JSON 中，`response` 欄位包含 AI 的回答\n",
    "\n",
    "## 下一步\n",
    "\n",
    "在下一個範例中，我們將學習如何進行多輪對話，讓 AI 記住對話的上下文！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
